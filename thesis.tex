%%%%%
%%
%% Sample document ``thesis.tex''
%%
%% Version: v0.2
%% Authors: Jean Martina, Rok Strnisa, Matej Urbas
%% Date: 30/07/2008
%%
%% Copyright (c) 2008-2011, Rok Strni≈°a, Jean Martina, Matej Urbas
%% License: Simplified BSD License
%% License file: ./License
%% Original License URL: http://www.freebsd.org/copyright/freebsd-license.html
%%%%%

% Available documentclass options:
%
%   <all `report` document class options, e.g.: `a5paper`>
%   withindex   - enables the index. New index entries can be added through `\index{my entry}`
%   glossary    - enables the glossary.
%   techreport  - typesets the thesis in the technical report format.
%   firstyr     - formats the document as a first-year report.
%   times       - uses the `Times` font.
%   backrefs    - add back references in the Bibliography section
%
% For more info see `README.md`
\documentclass[withindex,glossary]{cam-thesis}

% Citations using numbers
\usepackage[numbers]{natbib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis meta-information
%%

%% The title of the thesis:
\title{Towards Provenance as a Construct of \\
Dependable Computing Systems}

% Alternate titles
% Provenance based trustworthiness assessment in computing systems

%% The full name of the author (e.g.: James Smith):
\author{Nikilesh Balakrishnan}

%% College affiliation:
\college{Churchill College}

%% College shield [optional]:
% \collegeshield{CollegeShields/Christs}
\collegeshield{CollegeShields/Churchill}
% \collegeshield{CollegeShields/Clare}
% \collegeshield{CollegeShields/ClareHall}
% \collegeshield{CollegeShields/CorpusChristi}
% \collegeshield{CollegeShields/Darwin}
% \collegeshield{CollegeShields/Downing}
% \collegeshield{CollegeShields/Emmanuel}
% \collegeshield{CollegeShields/Fitzwilliam}
% \collegeshield{CollegeShields/Girton}
% \collegeshield{CollegeShields/GonCaius}
% \collegeshield{CollegeShields/Homerton}
% \collegeshield{CollegeShields/HughesHall}
% \collegeshield{CollegeShields/Jesus}
% \collegeshield{CollegeShields/Kings}
% \collegeshield{CollegeShields/LucyCavendish}
% \collegeshield{CollegeShields/Magdalene}
% \collegeshield{CollegeShields/MurrayEdwards}
% \collegeshield{CollegeShields/Newnham}
% \collegeshield{CollegeShields/Pembroke}
% \collegeshield{CollegeShields/Peterhouse}
% \collegeshield{CollegeShields/Queens}
% \collegeshield{CollegeShields/Robinson}
% \collegeshield{CollegeShields/Selwyn}
% \collegeshield{CollegeShields/SidneySussex}
% \collegeshield{CollegeShields/StCatharines}
% \collegeshield{CollegeShields/StEdmunds}
% \collegeshield{CollegeShields/StJohns}
% \collegeshield{CollegeShields/Trinity}
% \collegeshield{CollegeShields/TrinityHall}
% \collegeshield{CollegeShields/Wolfson}
% \collegeshield{CollegeShields/FitzwilliamRed}

%% Submission date [optional]:
% \submissiondate{November, 2042}

%% You can redefine the submission notice [optional]:
% \submissionnotice{A badass thesis submitted on time for the Degree of PhD}

%% Declaration date:
\date{September, 2017}

%% PDF meta-info:
\subjectline{Computer Science}
\keywords{Provenance Dependable Assurance}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract:
%%
\abstract{%
\begin{itemize} % TODO: this is just a placeholder
\item Provenance capture in computing systems.
\item Use of provenance to reason about computations in the context of control flow and data flow.
\item We provide real implementations of systems that allows us to track computations in the context of scientific computing.
\item We also provide a prototype implementation of tracing data flow in the context of disk I/O, from the application to the device and back.
\end{itemize}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements:
%%
\acknowledgements{%
  Add acknowledgements here ...
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Glossary [optional]:
%%
\newglossaryentry{HOL}{
    name=HOL,
    description={Higher-order logic}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Contents:
%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page, abstract, declaration etc.:
%% -    the title page (is automatically omitted in the technical report mode).
\frontmatter{}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body:
%%
\chapter{The Need For Provenance}

\section{The Problem}
\begin{itemize}
\item Computing has become ubiquitous and pervasive.
\item Generation of large amounts of data.
\item More computing performed and decisions taken based on this data.
\item These results are then used in all aspects of society: Business, Science, Social and Government.
\item Business example from insurance, banking and e-commerce. Link real articles.
\item Examples from scientific computing, look at papers on cancer research etc. Look for other research that publishes results on data.
\item These computations are much more interleaved and used by each other. Take for example the 2008 debt crisis:
\item Financial products were created on top of other financial products and derivatives and new products where nobody understood
what they were actually representing. c.f. when people took on the product they did not understand the risk they were actually taking on.
\item Impact of these computations ia huge. If the computation is wrong or inaccurate, it can have a huge impact on the structure of
society and/or have huge social, scientific, societal implications. Examples: e.g. Climate change controversy, Argentina Debt Crisis,
2008 Wall Street Crash etc.
\end{itemize}

\section{The Hypothesis}
\begin{itemize}
\item It is possible to build abstractions that allow people to track the inputs, operations and outputs of a computation
(provenance of a computation) so that you can reason about it from both a time and space perspective as you use the data
produced by the computation.
\item Having this support will allow us to mitigate the trust issues that arise from non-ascertainable computations.
\end{itemize}


\section{Thesis outline}
\begin{itemize}
\item In this thesis I explore the fundamental primitives required to build systems that offer provenance as a first-class construct
of systems.
\item To this end I focus on two systems:
(i) OPUS: A system for adding control-flow provenance to scientific computational pipelines.
(ii) NORAD: Non-repudiable assertions for disk I/O. NORAD is a system for asserting about data-flow in a computational system.
\item For each of these systems I provide real-world engineering systems and outline the design-space, implementation and use-cases for these systems.
\item I conclude by offering a look into further directions.
\end{itemize}

\section{Contributions}
The contributions of this thesis are thus:
\begin{itemize}
\item Design and implementation of a provenance system called OPUS, for scientists.
\item Tools and applications that utilise this system to show its utility in the context of scientific computation.
\item A performance characterisation of the system compared to existing systems.
\item A prototype system, NORAD for asserting the data provenance captured by provenance systems.
\item A characterisation of NORAD's performance and use-cases showing its utility.
\end{itemize}

\chapter{A Background into Provenance}
This chapter presents the background literature in the area of provenance.
\begin{itemize}
\item What is provenance and what is the use of provenance? A systematic capture of meta-data that describes the where, when and how of data and computations.
\item Meta-data is typically a graph that describes relationships between various elements or entities in a system that contributed to a piece of data produced by the system.
\item How is it captured?
\item Brief introduction into the various capture approaches used, system, workflow, database, etc. Our interest is in providing this support at the system level.
\item Therefore we focus on those mechanisms that capture provenance at the system call, filesystem and OS layers.
\item Introduce the concept of granularity of capture, the layer at which the capture happens and what the provenance describes at each layer of abstraction.
\item How provenance can be queried and used?
\item What about the security of the provenance itself? Current state-of-art in provenance security is the SPROV work that ensures the integrity and authenticity if provenance records once its captured.
\item What about provenance that was circumvented or falsified at the point of capture?
\item Cite the Primer on Provenance paper.
\end{itemize}

\chapter{OPUS: Control-flow Provenance Support for Scientists}
The work described in this chapter is a joint contribution with Thomas Bytheway. My primary contribution in this body of work is as follows:

\begin{itemize}
\item Equal intellectual contribution with Thomas Bytheway in the system design of OPUS.
\item Participated and contributed in the discussions on PVM, especially in modelling corner cases using PVM.
\item Implemented most of the interposition mechanism in the OPUS front-end.
\item Re-implemented parts of the OPUS backend to work with a graph database store, Neo4J.
\end{itemize}

\section{Introduction}
In ~\ref{ch:two} we have seen previous approaches for provenance capture, query and some real-world use-cases for provenance. In this chapter we attempt to outline the shortcomings of existing provenance systems, detailing the problems as the motivation for the design and implementation of OPUS, a user-space provenance capture, analysis and query tool for scientific computing. We show that it is possible to build tools and applications that can use this provenance captured to aid in tracking, archiving and debugging of multi-step ad hoc scientific computations.

\section{Motivation}
Today most physical sciences are computation based.
At its core, scientific computations involve the development of models and simulations to understand the natural world. 
These models and simulations are typically composed of multiple computational steps where data is input and output within each step, forming an experiment pipeline wherein data output in a step is used as input in the next step.
Once a result is obtained and interpreted, confidence in the result is obtained by analysing, repeating and reproducing the experiment independently.
In order to do this scientists have traditionally used manual and ad hoc techniques to record the data inputs and contexts (parameters, configuration, dependencies etc.) used in the computations to produce the result.
This manual process is however prone to errors and often not complete, resulting in experiments not being reproducible ~\cite{non-rep, nature}. 
Provenance systems ~\cite{PASS, BURRITO, StoyBook} have attempted to automate this effort and ease the process of reproducibility by automatically tracking data and computation.
However, these systems have lacked adoption in the real-world and have merely resulted in being research or experimental prototypes.
This is mainly because these systems are not widely available or easily deployable in practice.
Most of these systems require changes to the existing scientific workflow, require modification to the underlying OS or require the use of specialised systems.
Our goal is to design and implement a lightweight, general purpose provenance system that has a minimum barrier to entry in the context of scientific computing.
To this end, we have designed OPUS, a provenance system that has been designed to work entirely in user-space and is based on several key design principles discussed in the next section ~\ref{sec:constraints}.

%\begin{itemize}
%\item Today all the physical sciences are computation based. The results and research outcomes produced are strongly dependant on the correctness of data and computations. 
%\item We need a mechanism to reason about the trustworthiness of data and of computation. In this chapter we describe OPUS, which is a system for provenance capture, analysis and query.
%\item We've specifically targeted scientific applications as there is a pressing need for provenance to build tools for reproducibility, reason about trust/confidence in results
%and share or archive experiments for reference.
%\item We've seen a number of approaches previously towards implementing general purpose provenance capture and query systems.
%\item Most of these systems have resulted in prototype implementations which have lacked adoption in the real-world.
%\item This is because these systems are not widely available or easily deployable.
%\item Most of these systems require changes to the existing workflow, require specialised kernels etc.
%\item Our goal is to design and implement a lightweight general purpose provenance system that can drop into and easily integrate with existing systems.
%\item To this end we've designed and implemented OPUS.
%\end{itemize}

\section{A unique constraint space}
OPUS draws inspiration from previous approaches to building general purpose provenance systems but addresses the shortcomings in these systems outlined in ~\ref{sec:opusmotiv}. The design of OPUS is based on the following principles:

\begin{itemize}

\item \textbf{Non-intrusive:}
It is our observation that most computational scientists seldom have \texttt{root} or system level access to install and update software. Therefore it is important for a general purpose system to be as non-intrusive as possible i.e. the system should not require changes to the underlying OS or the use of bespoke kernel modules to capture provenance. Therefore a major design principle for OPUS is that it must work entirely in user-space. An added advantage of designing OPUS to work in user-space is that it becomes easier to ensure that in a shared system, users of OPUS not affect other users in the system.

\item \textbf{Ease of installation:}
In addition to being non-intrusive a general purpose provenance system must be easy to install, i.e. the installation must be self-contained, having no external dependencies and requiring minimal configuration changes. This ensures that the barrier to adoption of such systems by users such as scientists is as low as possible.

\item \textbf{Seamlessness:}
Scientific computing across disciplines are diverse in terms of the workflow used, therefore a general purpose provenance system should not require the end user to modify his/her workflow in order to use the system. Therefore OPUS should be designed to drop into a user's environment and seamlessly integrate with existing workflows and capture provenance.

\item \textbf{Low overheads:} 
Scientific applications are typically executed multiple times and each run can perform multiple iterations until the computation converges to a specific expected result. This execution could therefore take anywhere from seconds to minutes to hours depending on the complexity of the computation performed. Therefore it is important that a provenance system like OPUS impart minimal overheads on the application run time. Similarly, the application could be executing in memory and storage constrained environments, therefore keeping the spatial overheads low is also a useful property to consider while designing the system.

\item \textbf{Completeness:} 
Existing systems record only a subset of operations applications perform on files and processes. This restricts the range of provenance queries that one can implement. To support a richer set of queries OPUS should be designed to capture all file and process mutating operations. Similarly, merely capturing file and process interactions ignores the execution context (library versions used, command line parameters used, environment variables etc.) in which these operations were done. Therefore the mechanism OPUS uses should capture the underlying execution context as well. 

\item \textbf{Reasoning about provenance:}
The ultimate goal of capturing provenance is to use the provenance to reason about application and system execution. However, provenance is itself represented as data and we require a mechanism to reason about changes made to provenance data as it is transformed. Existing systems use ad-hoc approaches to reason about the provenance data captured. In order for provenance to be useful and effective, we require a more formal approach to to reason about the provenance data itself. In the following section ~\ref{sec:pvm} we discuss PVM, a semi-formal model to reason about provenance captured.

\end{itemize}

\section{Reasoning About Provenance}
The theoretical contribution of this work belongs to Thomas Bytheway.
Acknowledge that this is joint work with Thomas Bytheway.
\begin{itemize}
\item What is a provenance object? History or lineage of digital entities (files, sockets, pipes etc.). Entities modelled as objects and versioned.
\item What is a provenance object version? Version of an object represents the state of an entity at a give time in its history. Versions are chained together to allow us to reason about the history of an entity in its lifetime.
\item What versioning schemes exist? Version on write, Open-to-Close versioning.
\item What is PVM? Definable versioning semantics.
\item How does PVM simplify our ability to reason about provenance?
Formalises the concept of tracking and recording changes in system entities.
Formalises the versioning side-effects of concurrent updates to system entities.
\end{itemize}

\section{Implementation}
\begin{itemize}
\item Considered a number of capture options. We require a fairly fine granularity of capture but in user-space.
\item A number of options to evaluate, ptrace, tracing tools (dtrace, system tap etc), kprobes, linux audit etc.
\item Our requirement is for the capture to happen entirely in user-space and for the overheads to be as minimal as possible.
\item We use Library level interposition mechanism (LD\_PRELOAD) to override the standard C library symbols that the application invokes.
\item To ease development effort for interposition, we implemented code generation using templating. We defined a DSL that can be used to generate boilerplate code.
\item Introducing this interposition layer could potentially change the semantics of the application being interposed, we therefore must maintain semantic equivalence with Poisix.
\item These problems are covered in the TaPP'14 paper.
\item A backend receives syscall or library call information and converts it into provenance based on PVM (see next section) that builds relationships between input and output, application context and program executions.
\item Initial use of levelDB. Change to use Neo4J to enable easier graph traversal.
\end{itemize}

\section{Evaluation}
\begin{itemize}
\item Temporal overheads of using OPUS. (Interposition overheads)
\item Pathological case, \texttt{man} command. Single char reads and writes. (should this be in implementation?)
\item Optimisations performed, aggregation, OPUS Lite etc. (implementation?)
\item Performance evaluation of the analyser backend. Cost of DB operations.
\item Spatial overheads: Average space used to store provenance, for scientific workloads.
\item Comparing Neo4J with SQLite?
\end{itemize}

\section{Provenance tools for Scientists}
\begin{itemize}
\item Debug system change. Detect changes in environment, command line params, library versions linked etc.
\item Workflow Tracking. Capture scientific workflow from ad-hoc steps. Tools to visualise and scriptise the workflow.
\item Archiving. EPSRC mandate to provide code and data used to produce results. Workflow archive tool, enables scientists to archive and upload their code and data used in experiments.
% NOTE: Maybe merge workflow tracking and archiving into one tool?
\end{itemize}


\chapter{NORAD: Non-Repudiable Assertions for Disk I/O}
\section{Motivation}
\begin{itemize}
\item Previous chapter looked at adding control-flow provenance but we don't actually do data-flow provenance, we assume existing mechanisms are leveraged to support data provenance.
\item However, the achilles heel in such a system is reasoning about the trustworthiness and correctness of data.
\item Correctness has previously been solved using crypto techniques, hashing, checksumming, encryption etc.
\item Onus on the application to use these techniques. However, this still not sufficient.
\item Applications must trust the underlying OS to faithfully perform their I/O.
\item OSes get routinely compromised and this questions the trustworthiness of data and its provenance.
\item In this chapter we set out to solve the issue of trustworthiness of data for the purposes of asserting and correlating control-flow provenance collected with the data on the system.
\item Can we do this with the OS out of the trust boundary?
\end{itemize}

\section{Trusted Execution of applications on Untrusted OSes}
\begin{itemize}
\item Talk about InkTag, Sego etc.
\item SGX, hardware assisted inverse sandbox for the secure execution of applications on untrusted system software.
\end{itemize}

\section{NORAD}
\begin{itemize}
\item Threat Model and TCB.
\item Use of SGX for trusted execution of applications.
\item How data provenance is captured from application to device.
\item APSYS'17 paper.
\end{itemize}

\subsection{Prototype}
\begin{itemize}
\item Library to perform raw block reads and writes.
\item Emulation of firmware on a stackable block device driver.
\end{itemize}

\subsection{Evaluation}
\begin{itemize}
\item Latency and Throughput compared to \texttt{dd} performing direct I/O.
\item Use of different block sizes.
\item compare use of cmac vs vmac.
\item Use of hotcalls to avoid context switching.
\end{itemize}

\chapter{Future Directions and Conclusions}
\begin{itemize}
\item Integration with a real-world filesystem.
\item User of smart devices to verify OS actions.
\item Approaches:
(i) Execute enclave code within the kernel.
(ii) Use of a block based FUSE file system implementation.
(iii) Use of smart SSDs and USBs to verify OS requests.
\item Extend design to other forms of I/O, specifically network I/O.

\item Conclusions: 
(i) Shown that its possible to build systems for control-flow provenance and data-flow provenance.
(ii) Building blocks for provenance as a first class construct.
\end{itemize}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Bibliography:
%%
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{plainnat}
\bibliography{thesis}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Appendix:
%%

\appendix

\chapter{Extra Information}
Some more text ...



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Index:
%%
\printthesisindex

\end{document}
